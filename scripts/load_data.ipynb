{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ccd0bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Loading dataset: myocardial\n",
      "    Source: myocardial\n",
      "    [myocardial Cleaning] Dropped 0 constant columns.\n",
      "    Raw Data Shape: 1700 rows x 111 features\n",
      "    Computed Correlation Matrix A: (111, 111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        , -0.37434968,  0.08990689, ..., -0.05034158,\n",
       "         -0.05099073, -0.03022833],\n",
       "        [-0.37434968,  1.        ,  0.03998751, ..., -0.00922243,\n",
       "          0.02960847,  0.05883139],\n",
       "        [ 0.08990689,  0.03998751,  1.        , ..., -0.04475086,\n",
       "         -0.01392607,  0.01097591],\n",
       "        ...,\n",
       "        [-0.05034158, -0.00922243, -0.04475086, ...,  1.        ,\n",
       "         -0.10236636, -0.21385819],\n",
       "        [-0.05099073,  0.02960847, -0.01392607, ..., -0.10236636,\n",
       "          1.        ,  0.05558756],\n",
       "        [-0.03022833,  0.05883139,  0.01097591, ..., -0.21385819,\n",
       "          0.05558756,  1.        ]], shape=(111, 111)),\n",
       " array([[ 1.28601462,  0.77216846,  1.73022388, ...,  0.59818682,\n",
       "         -0.13403012, -0.50091895],\n",
       "        [-0.54708801,  0.77216846,  0.53405446, ...,  0.59818682,\n",
       "         -0.13403012,  1.99633095],\n",
       "        [-0.79705655,  0.77216846, -0.66211495, ...,  0.59818682,\n",
       "         -0.13403012, -0.50091895],\n",
       "        ...,\n",
       "        [-0.54708801,  0.77216846,  2.9263933 , ...,  0.59818682,\n",
       "         -0.13403012, -0.50091895],\n",
       "        [ 1.45266032, -1.29505419,  1.73022388, ...,  0.59818682,\n",
       "         -0.13403012, -0.50091895],\n",
       "        [ 0.11949477,  0.77216846,  1.73022388, ..., -1.67171853,\n",
       "         -0.13403012, -0.50091895]], shape=(1700, 111)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Registry of supported datasets\n",
    "DATASETS_URL = {\n",
    "    \"residential\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/00437/Residential-Building-Data-Set.xlsx\",\n",
    "    \"secom\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\",\n",
    "    \"arrhythmia\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data\",\n",
    "}\n",
    "\n",
    "DATASETS_ID = {\"myocardial\": 579}\n",
    "\n",
    "\n",
    "def load_dataset_online(name_or_url):\n",
    "    \"\"\"\n",
    "    General entry point to load any supported CSSP dataset.\n",
    "\n",
    "    Args:\n",
    "        name_or_url (str): Either a key ('residential', 'secom') or a direct URL.\n",
    "\n",
    "    Returns:\n",
    "        A (np.ndarray): Correlation matrix (p x p).\n",
    "        X_norm (np.ndarray): Normalized feature matrix (N x p).\n",
    "    \"\"\"\n",
    "    # 1. Resolve URL\n",
    "    url = DATASETS_URL.get(name_or_url.lower(), name_or_url)\n",
    "\n",
    "    print(f\"  > Loading dataset: {name_or_url}\")\n",
    "    print(f\"    Source: {url}\")\n",
    "\n",
    "    try:\n",
    "        if name_or_url in DATASETS_URL:\n",
    "            # 2. Download Data (Robust SSL handling)\n",
    "            response = requests.get(url, verify=False)\n",
    "            response.raise_for_status()\n",
    "            content = io.BytesIO(response.content)\n",
    "\n",
    "            # 3. Dispatch to specific loader based on known URLs\n",
    "            if \"Residential-Building\" in url:\n",
    "                X_raw = _parse_residential(content)\n",
    "            elif \"secom\" in url:\n",
    "                X_raw = _parse_secom(content)\n",
    "            elif \"arrhythmia\" in url:\n",
    "                X_raw = _parse_arrhythmia(content)\n",
    "            else:\n",
    "                # Fallback: Try generic CSV loading\n",
    "                print(\"    Unknown format. Attempting generic CSV load...\")\n",
    "                df = pd.read_csv(content)\n",
    "                X_raw = df.select_dtypes(include=[np.number]).to_numpy()\n",
    "\n",
    "            if X_raw is None:\n",
    "                return None, None\n",
    "        elif name_or_url in DATASETS_ID:\n",
    "            if \"myocardial\" in name_or_url:\n",
    "                X = fetch_ucirepo(id=DATASETS_ID[\"myocardial\"]).data.features\n",
    "                X_raw = _parse_myocardial(X)\n",
    "        # 4. Standardize and Compute Correlation (Shared Logic)\n",
    "        return _standardize_and_correlate(X_raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    CRITICAL ERROR loading data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# --- SPECIFIC PARSERS ---\n",
    "\n",
    "\n",
    "def _parse_residential(content):\n",
    "    \"\"\"Parser for UCI Residential Building (Excel, Headers, targets at end).\"\"\"\n",
    "    try:\n",
    "        # Read Excel (Header is on row 1, index 1)\n",
    "        df = pd.read_excel(content, header=1)\n",
    "\n",
    "        # Columns 4 to 107 are the features (V-1 to V-104)\n",
    "        # Drop first 4 (ID/Dates) and last 2 (Targets)\n",
    "        X_df = df.iloc[:, 4:107]\n",
    "\n",
    "        # Force numeric\n",
    "        X_raw = X_df.apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float64)\n",
    "        return np.nan_to_num(X_raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Error parsing Residential Excel: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _parse_secom(content):\n",
    "    \"\"\"Parser for SECOM (Space-separated, No Header, Constant Columns).\"\"\"\n",
    "    try:\n",
    "        # Read CSV with space delimiter\n",
    "        df = pd.read_csv(content, sep=r\"\\s+\", header=None)\n",
    "        X_raw = df.to_numpy(dtype=np.float64)\n",
    "\n",
    "        # Fill NaNs (SECOM has many)\n",
    "        X_raw = np.nan_to_num(X_raw)\n",
    "\n",
    "        return _clean_constant_rows(X_raw, \"secom\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Error parsing SECOM CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _parse_arrhythmia(content):\n",
    "    \"\"\"Parser for Arrhythmia (Comma-separated, '?' for missing data).\"\"\"\n",
    "    try:\n",
    "        # FIX 1: Use sep=\",\" (default) and handle '?' missing values\n",
    "        df = pd.read_csv(content, header=None, na_values=\"?\")\n",
    "\n",
    "        # FIX 2: Arrhythmia often has a 'class' label in the last column\n",
    "        # Usually for CSSP we only want the features (columns 0-278)\n",
    "        X_df = df.iloc[:, :-1]\n",
    "\n",
    "        # Force numeric and fill NaNs with 0\n",
    "        X_raw = (\n",
    "            X_df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "            .fillna(0)\n",
    "            .to_numpy(dtype=np.float64)\n",
    "        )\n",
    "\n",
    "        return _clean_constant_rows(X_raw, \"arrhythmia\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Error parsing Arrhythmia CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "def _parse_myocardial(content):\n",
    "    try:\n",
    "        X_raw = content.apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy(dtype=np.float64)\n",
    "        \n",
    "        return _clean_constant_rows(X_raw, \"myocardial\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error parsing Arrhythmia CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- SHARED MATH ---\n",
    "\n",
    "\n",
    "def _clean_constant_rows(X_raw, name):\n",
    "    \"\"\"Drop constant rows (Repeated rows)\"\"\"\n",
    "    # SECOM SPECIFIC: Drop constant columns (Variance = 0)\n",
    "        # If we don't do this, the matrix is singular and solver crashes.\n",
    "    std_devs = np.std(X_raw, axis=0)\n",
    "    keep_idx = np.where(std_devs > 1e-9)[0]\n",
    "\n",
    "    print(\n",
    "        f\"    [{name} Cleaning] Dropped {X_raw.shape[1] - len(keep_idx)} constant columns.\"\n",
    "    )\n",
    "    return X_raw[:, keep_idx]\n",
    "\n",
    "def _standardize_and_correlate(X_raw):\n",
    "    \"\"\"\n",
    "    Normalizes X (Z-score) and calculates A = (X^T X) / N.\n",
    "    Used for ALL datasets to ensure consistent math.\n",
    "    \"\"\"\n",
    "    N, p = X_raw.shape\n",
    "    print(f\"    Raw Data Shape: {N} rows x {p} features\")\n",
    "\n",
    "    # Z-score Normalization\n",
    "    X_mean = np.mean(X_raw, axis=0)\n",
    "    X_std = np.std(X_raw, axis=0)\n",
    "\n",
    "    # Safety: Avoid division by zero\n",
    "    X_std[X_std == 0] = 1.0\n",
    "\n",
    "    X_norm = (X_raw - X_mean) / X_std\n",
    "\n",
    "    # Correlation Matrix\n",
    "    A = (X_norm.T @ X_norm) / N\n",
    "\n",
    "    print(f\"    Computed Correlation Matrix A: {A.shape}\")\n",
    "    return A, X_norm\n",
    "\n",
    "\n",
    "\n",
    "load_dataset_online(\"myocardial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d07f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "777d6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "myocardial = fetch_ucirepo(id=579)\n",
    "X = myocardial.data.features\n",
    "Y = myocardial.data.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d5e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_raw = X.apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0742ecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.,  1.,  2., ...,  1.,  0.,  0.],\n",
       "       [55.,  1.,  1., ...,  1.,  0.,  1.],\n",
       "       [52.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       ...,\n",
       "       [55.,  1.,  3., ...,  1.,  0.,  0.],\n",
       "       [79.,  0.,  2., ...,  1.,  0.,  0.],\n",
       "       [63.,  1.,  2., ...,  0.,  0.,  0.]], shape=(1700, 111))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f79ecc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = np.nan_to_num(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af9e92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant columns\n",
    "std_devs = np.std(X_raw, axis=0)\n",
    "keep_idx = np.where(std_devs > 1e-9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4894200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_count = X_raw.shape[1] - len(keep_idx)\n",
    "if dropped_count > 0:\n",
    "    print(f\"Cleaning Dropped {dropped_count} constant column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20f8bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X_raw[: , keep_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f4820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Error parsing Residential Excel: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# def load_dataset_local(name):\n",
    "#     \"\"\"Load dataset from local\"\"\"\n",
    "#     try:\n",
    "#         DATA_DIR = Path(__file__).resolve().parent / \"data\"\n",
    "#     except NameError:\n",
    "#         DATA_DIR = Path(os.getcwd()).resolve().parent / \"data\"\n",
    "#     try:\n",
    "#         if \"protein\" in name:\n",
    "#             df = pd.read_csv(DATA_DIR / \"protein\" / \"secondary-structure.data\")\n",
    "#             return df\n",
    "#     except Exception as e:\n",
    "#         print(f\"    Error parsing Residential Excel: {e}\")\n",
    "#         return None\n",
    "\n",
    "    \n",
    "# load_dataset_local(\"protein\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
