{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d515f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: synthetic_high_corr\n",
      "============================================================\n",
      "  > Loading dataset: synthetic_high_corr\n",
      "    Generating Synthetic Data: N=2000, p=500, Blocks=1, Corr=0.95\n",
      "    Computed Correlation Matrix A: (500, 500)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 2000\n",
      "    Columns (Features): 500\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.9973\n",
      "    Maximum Feature Correlation: 0.9976\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000  0.9973  0.9972  0.9972  0.9973\n",
      "1  0.9973  1.0000  0.9972  0.9971  0.9973\n",
      "2  0.9972  0.9972  1.0000  0.9972  0.9974\n",
      "3  0.9972  0.9971  0.9972  1.0000  0.9973\n",
      "4  0.9973  0.9973  0.9974  0.9973  1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: residential\n",
      "============================================================\n",
      "  > Loading dataset: residential\n",
      "    Source: https://archive.ics.uci.edu/ml/machine-learning-databases/00437/Residential-Building-Data-Set.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nautilus/gridfw/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'archive.ics.uci.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Raw Data Shape: 372 rows x 103 features\n",
      "    Computed Correlation Matrix A: (103, 103)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 372\n",
      "    Columns (Features): 103\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.5868\n",
      "    Maximum Feature Correlation: 1.0000\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000 -0.2295 -0.1381 -0.2869 -0.3136\n",
      "1 -0.2295  1.0000  0.9465  0.7695  0.2266\n",
      "2 -0.1381  0.9465  1.0000  0.6392  0.1544\n",
      "3 -0.2869  0.7695  0.6392  1.0000  0.5823\n",
      "4 -0.3136  0.2266  0.1544  0.5823  1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: secom\n",
      "============================================================\n",
      "  > Loading dataset: secom\n",
      "    Source: https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nautilus/gridfw/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'archive.ics.uci.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [secom Cleaning] Dropped 112 constant columns.\n",
      "    Raw Data Shape: 1567 rows x 478 features\n",
      "    Computed Correlation Matrix A: (478, 478)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 1567\n",
      "    Columns (Features): 478\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.0429\n",
      "    Maximum Feature Correlation: 1.0000\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000 -0.0478  0.0076  0.0094 -0.0009\n",
      "1 -0.0478  1.0000 -0.0304  0.0060  0.0022\n",
      "2  0.0076 -0.0304  1.0000  0.3238  0.0204\n",
      "3  0.0094  0.0060  0.3238  1.0000 -0.0540\n",
      "4 -0.0009  0.0022  0.0204 -0.0540  1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: arrhythmia\n",
      "============================================================\n",
      "  > Loading dataset: arrhythmia\n",
      "    Source: https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nautilus/gridfw/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'archive.ics.uci.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [arrhythmia Cleaning] Dropped 17 constant columns.\n",
      "    Raw Data Shape: 452 rows x 262 features\n",
      "    Computed Correlation Matrix A: (262, 262)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 452\n",
      "    Columns (Features): 262\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.0890\n",
      "    Maximum Feature Correlation: 1.0000\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000 -0.0590 -0.1095  0.3816 -0.0040\n",
      "1 -0.0590  1.0000 -0.1247 -0.2481 -0.3371\n",
      "2 -0.1095 -0.1247  1.0000 -0.0750 -0.0063\n",
      "3  0.3816 -0.2481 -0.0750  1.0000  0.1001\n",
      "4 -0.0040 -0.3371 -0.0063  0.1001  1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: mnist\n",
      "============================================================\n",
      "  > Loading dataset: mnist\n",
      "    Fetching MNIST from OpenML (this may take a moment)...\n",
      "    [mnist Cleaning] Dropped 145 constant columns.\n",
      "    Raw Data Shape: 2000 rows x 639 features\n",
      "    Computed Correlation Matrix A: (639, 639)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 2000\n",
      "    Columns (Features): 639\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.0662\n",
      "    Maximum Feature Correlation: 1.0000\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000  1.0000 -0.0005 -0.0007 -0.0007\n",
      "1  1.0000  1.0000 -0.0005 -0.0007 -0.0007\n",
      "2 -0.0005 -0.0005  1.0000  0.9234  0.0934\n",
      "3 -0.0007 -0.0007  0.9234  1.0000  0.4230\n",
      "4 -0.0007 -0.0007  0.0934  0.4230  1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ANALYZING DATASET: madelon\n",
      "============================================================\n",
      "  > Loading dataset: madelon\n",
      "    Fetching Madelon from OpenML...\n",
      "    Raw Data Shape: 2600 rows x 500 features\n",
      "    Computed Correlation Matrix A: (500, 500)\n",
      "\n",
      "[1] DATASET DIMENSIONS\n",
      "    Rows: 2600\n",
      "    Columns (Features): 500\n",
      "\n",
      "[2] COMPUTING COLUMN CORRELATIONS...\n",
      "\n",
      "[3] REDUNDANCY STATISTICS\n",
      "    Average Feature Correlation: 0.0160\n",
      "    Maximum Feature Correlation: 0.9904\n",
      "\n",
      "[4] SAMPLE CORRELATION BLOCK (First 5 Features)\n",
      "    This shows how similar the first few features are to each other:\n",
      "        0       1       2       3       4\n",
      "0  1.0000  0.0201 -0.0321 -0.0048 -0.0085\n",
      "1  0.0201  1.0000 -0.0137  0.0077  0.0245\n",
      "2 -0.0321 -0.0137  1.0000  0.0081  0.0003\n",
      "3 -0.0048  0.0077  0.0081  1.0000 -0.0036\n",
      "4 -0.0085  0.0245  0.0003 -0.0036  1.0000\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from grad_fw.data_loader import DatasetLoader\n",
    "\n",
    "def analyze_feature_correlation(dataset_name, n_samples=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Loads a dataset and computes the pairwise Pearson correlation between its columns (features).\n",
    "    Prints statistics to prove feature redundancy.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset (e.g., 'synthetic_high_corr', 'residential').\n",
    "        n_samples (int, optional): Limit rows for speed (e.g., 2000). None uses all data.\n",
    "        **kwargs: Extra arguments for synthetic generation (e.g., n_blocks=1).\n",
    "    \"\"\"\n",
    "    loader = DatasetLoader()\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANALYZING DATASET: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Load Data\n",
    "    # Note: We rely on the loader to return 'A' (matrix) and 'X_norm' (the actual data).\n",
    "    # We only care about X_norm here.\n",
    "    try:\n",
    "        _, X_raw = loader.load(dataset_name, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")\n",
    "        return\n",
    "\n",
    "    if X_raw is None:\n",
    "        print(\"Dataset not found or failed to load.\")\n",
    "        return\n",
    "\n",
    "    # Subsample rows if requested (does not affect column correlation logic, just speed)\n",
    "    if n_samples and X_raw.shape[0] > n_samples:\n",
    "        X_raw = X_raw[:n_samples]\n",
    "\n",
    "    # 2. Convert to Pandas for easy Correlation calculation\n",
    "    df = pd.DataFrame(X_raw)\n",
    "    n_rows, n_cols = df.shape\n",
    "    \n",
    "    print(f\"\\n[1] DATASET DIMENSIONS\")\n",
    "    print(f\"    Rows: {n_rows}\")\n",
    "    print(f\"    Columns (Features): {n_cols}\")\n",
    "\n",
    "    # 3. Compute Full Correlation Matrix (Feature vs Feature)\n",
    "    print(\"\\n[2] COMPUTING COLUMN CORRELATIONS...\")\n",
    "    corr_matrix = df.corr().abs() # We use absolute value to treat -0.99 same as 0.99\n",
    "\n",
    "    # 4. Extract Key Statistics\n",
    "    # Mask the diagonal (which is always 1.0) to find true cross-correlations\n",
    "    mask = np.ones(corr_matrix.shape, dtype=bool)\n",
    "    np.fill_diagonal(mask, 0)\n",
    "    off_diag_corrs = corr_matrix.values[mask]\n",
    "\n",
    "    avg_corr = np.mean(off_diag_corrs)\n",
    "    max_corr = np.max(off_diag_corrs)\n",
    "    \n",
    "    # 5. Proof: Specific Examples\n",
    "    print(f\"\\n[3] REDUNDANCY STATISTICS\")\n",
    "    print(f\"    Average Feature Correlation: {avg_corr:.4f}\")\n",
    "    print(f\"    Maximum Feature Correlation: {max_corr:.4f}\")\n",
    "\n",
    "    # Show a specific high-correlation pair\n",
    "    # Find indices of max correlation\n",
    "    # We flatten the matrix, find argmax, then unravel index\n",
    "    # (Using a simpler loop for clarity in output)\n",
    "    \n",
    "    print(f\"\\n[4] SAMPLE CORRELATION BLOCK (First 5 Features)\")\n",
    "    print(\"    This shows how similar the first few features are to each other:\")\n",
    "    print(df.iloc[:, :5].corr().round(4))\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# EXECUTION EXAMPLES\n",
    "# ==========================================\n",
    "\n",
    "# 1. Test your \"Dense\" Synthetic Data (The one for the email)\n",
    "# This proves the \"All columns are clones\" argument\n",
    "analyze_feature_correlation(\n",
    "    \"synthetic_high_corr\", \n",
    "    n_blocks=1, \n",
    "    correlation_strength=0.95\n",
    ")\n",
    "\n",
    "# 2. Test Real Data (Residential)\n",
    "# This likely has lower average correlation, which explains why FW works differently here\n",
    "analyze_feature_correlation(\"residential\")\n",
    "analyze_feature_correlation(\"secom\")\n",
    "analyze_feature_correlation(\"arrhythmia\")\n",
    "analyze_feature_correlation(\"mnist\")\n",
    "analyze_feature_correlation(\"madelon\")\n",
    "\n",
    "# 3. Test Myocardial\n",
    "# analyze_feature_correlation(\"myocardial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
